{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0424cb64-4d4b-4e37-9b8d-4a7ba4e665ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e7bff630-f826-40a5-9665-9c682a0e3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('../data/data.csv',usecols=lambda x: x != \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58bac899-ff47-471e-a95a-c7973e0beff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "400aa47d-2291-4d48-bbf5-13a1ed67c2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['exercise_name', 'type_of_activity', 'type_of_equipment', 'body_part',\n",
       "       'type', 'muscle_groups_activated', 'instructions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c095c2f-7d82-470c-94da-b4147feec199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=0, column='id', value=df.index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f4e0561-56ab-488b-9d8d-080c68a8d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d660f404-0c15-4490-863f-e1216d2c8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields= df.columns.tolist()[1:],\n",
    "    keyword_fields= df.columns.tolist()[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fb2b7362-4d20-40b8-8469-34e7793b4f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7033e368fce0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8fd5a0c2-d367-425e-b09a-1b0128d1b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=index.search(\n",
    "        query='Push-up',\n",
    "        filter_dict={},\n",
    "        boost_dict={},\n",
    "        num_results=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "862e1d32-1fa3-4020-ba09-d5ad4a8d8767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "523a3b59-cc36-4658-96ed-675a5b3bce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "    results = index.search(query =query, filter_dict ={}, boost_dict=boost, num_results=10)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "07acece3-0265-4c43-897d-059f50b06ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a fitness insrtuctor. Answer the QUESTION based on the CONTEXT from our exercises database. \n",
    "Use only the facts from the CONTEXT when answering the QUESTION. Lastly, Answer should be translated to Traditional Chinese language.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "exercise_name: {exercise_name}\n",
    "type_of_activity: {type_of_activity}\n",
    "type_of_equipment: {type_of_equipment}\n",
    "body_part: {body_part}\n",
    "type: {type}\n",
    "muscle_groups_activated: {muscle_groups_activated}\n",
    "instructions: {instructions}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "43a912a0-f2af-4364-9353-a0d4d3109748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model_name = \"Qwen/Qwen3-1.7B\"):\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    import torch\n",
    "\n",
    "    # load the tokenizer and the model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\"\n",
    "    )    \n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    # conduct text completion\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=32768\n",
    "    )\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "    # parsing thinking content\n",
    "    try:\n",
    "        # rindex finding 151668 (</think>)\n",
    "        index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "    \n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    print(thinking_content)\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")    \n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6e1c7187-80bd-4ae6-90cb-3a5e5daff1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model_name = \"Qwen/Qwen3-1.7B\"):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model_name = model_name)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fcdd20eb-f935-4d1c-b782-c9d1115e30dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14eed59a5d7f46ff8653de1beba67ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's tackle this question. The user is asking if the Lat Pulldown is considered a strength training activity and why. \n",
      "\n",
      "First, I need to check the CONTEXT provided. Looking through the exercises, I see multiple entries for Lat Pulldown. All of them have \"type_of_activity: Strength\" which indicates that they are strength training exercises. The equipment varies, but it's always a machine or cable machine. The body part is Upper Body, and the muscle groups activated include the Latissimus Dorsi and Biceps. \n",
      "\n",
      "The instructions describe pulling the bar down to the chest, which is a common strength movement. The fact that it's categorized as strength training in all the entries supports that. The user might be confused if they think all these exercises are the same, but the context clearly states they are all strength activities. \n",
      "\n",
      "So the answer should confirm that yes, the Lat Pulldown is a strength training activity because it targets the latissimus dorsi and biceps, and the instructions involve resistance, which is a key aspect of strength training. The reason is the activation of specific muscles and the use of equipment to provide resistance.\n",
      "</think>\n",
      "Lat Pulldown 被視為強度訓練活動，原因在於其針對主要肌肉群（如菱形肌和二頭肌）進行訓練，並透過機械或繩索設備提供阻力，符合強度訓練的定義。\n"
     ]
    }
   ],
   "source": [
    "question = 'Is the Lat Pulldown considered a strength training activity, and if so, why?'\n",
    "answer = rag(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3623c9c-2447-4a0f-b502-c30a2018ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddaf7ae-1879-4580-9be7-6a631ea05508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-1.7B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe08585e-cb3e-41a3-82ce-f9a266bee591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6024a9257274b8aaca3b0cd3c4e9699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "539871a5-48e3-4432-b2b6-af4fe3d5c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model input\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0c210f7-86aa-4181-9f73-6d60e8d44db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29d2496b-a23b-4aff-b058-e6939e0f2f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Give me a short introduction to large language model.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba82c9be-ea5c-491e-8c98-92762bb07650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,    872,    198,  35127,    752,    264,   2805,  16800,    311,\n",
       "           3460,   4128,   1614,     13, 151645,    198, 151644,  77091,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9366d768-7c66-410c-8a7b-4fd8c54d0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b072e8e7-f15b-41f1-843a-b17f1c154d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5b4b944-c36b-48f7-bbcf-a27b199dce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, the user wants a short introduction to large language models. Let me start by defining what they are. Large language models are AI systems that can understand and generate human-like text. I should mention their key features like training on vast datasets, neural networks, and the ability to generate text on the fly.\n",
      "\n",
      "Wait, they might not know the specifics. I need to keep it simple. Maybe start with the basics: what they are, how they work, and their applications. Also, highlight their capabilities like language understanding, generation, and reasoning. Should I mention specific examples like GPT or BERT? Probably not necessary for a short intro. Focus on the general concept.\n",
      "\n",
      "Make sure to explain that they're trained on a lot of data, which allows them to learn patterns and generate coherent text. Also, note that they can be used in various fields like writing, coding, or customer service. Avoid jargon but keep it informative. Check for clarity and conciseness. Alright, that should cover the main points.\n",
      "</think>\n",
      "content: Large language models (LLMs) are advanced AI systems designed to understand, generate, and interact with human language. They are trained on vast datasets of text to learn patterns, syntax, and context, enabling them to produce coherent, context-aware responses. These models excel in tasks like writing, coding, answering questions, and more by leveraging neural networks to simulate human-like language processing. Their ability to adapt and learn continuously makes them versatile tools across industries, though they require significant computational resources and careful training to maintain accuracy and ethical standards.\n"
     ]
    }
   ],
   "source": [
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624fa51-4a71-4fde-872c-458f8ca20c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
